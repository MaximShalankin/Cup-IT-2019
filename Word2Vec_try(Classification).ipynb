{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python_storage\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мы считываем предобработанные данные, которые прошли через функцию tokenizer_best\n",
    "\n",
    "*данную функцию можно встретить в других ноутбуках моего репозитория*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем токены трэйна\n",
    "with open('token_train.pickle', 'rb') as dump_in:\n",
    "    token_train = pickle.load(dump_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем токены теста\n",
    "with open('token_test.pickle', 'rb') as dump_in:\n",
    "    token_test = pickle.load(dump_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = token_train + token_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем обучающую и тестовую выборки\n",
    "train = pd.read_csv('train_data.csv', encoding='utf', engine='python', index_col=0)\n",
    "test = pd.read_csv('test_data.csv', encoding='utf', engine='python', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели w2v и извлечение признаков из неё"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(size=300, min_count=1)\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 2min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2862194889, 3128013000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.train(sentences,total_examples=len(sentences),epochs=3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('автокредит', 0.5961386561393738),\n",
       " ('ипотека', 0.569599986076355),\n",
       " ('кредитный', 0.3977956175804138),\n",
       " ('рассрочка', 0.38397979736328125),\n",
       " ('кредитка', 0.38149750232696533),\n",
       " ('карта', 0.3735683560371399),\n",
       " ('сумма', 0.3481549620628357),\n",
       " ('досрочно', 0.347896933555603),\n",
       " ('потребительский', 0.34564313292503357),\n",
       " ('банк', 0.33431875705718994)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('кредит') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "def SentenceToAverageWeightedVector(wv, sentence):\n",
    "    \"\"\"Функция для извлечения признаков из обученной модели W2V\"\"\"\n",
    "    vectors = pandas.DataFrame()\n",
    "    index = 0\n",
    "    try:\n",
    "        for word in sentence:\n",
    "            if word in wv.vocab:\n",
    "                vectors[index] = wv[word]\n",
    "            index += 1\n",
    "        vectors = vectors.transpose()\n",
    "        vector = vectors.mean().values.tolist()\n",
    "    except Exception:\n",
    "        return []\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectors_merged_train = [SentenceToAverageWeightedVector(model.wv, senten) for senten in token_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectors_merged_test = [SentenceToAverageWeightedVector(model.wv, senten) for senten in token_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pd.factorize(train.type)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6585077635255752\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_scores = cross_val_score(estimator=clf, X=vectors_merged_train, y=y1,\n",
    "                scoring='accuracy',  \n",
    "                cv=10, #stratified by default\n",
    "                n_jobs=-1)\n",
    "print(np.mean(pred_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполним сеточный поиск параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression(#solver='newton-cg', \n",
    "                        n_jobs=-1,\n",
    "                        solver='lbfgs',\n",
    "                        penalty='l2',\n",
    "                        tol=0.000000001,\n",
    "                        random_state=42,\n",
    "                        C=10, \n",
    "                        max_iter=100000)\n",
    "lm_params = {#'penalty':[ 'l2'], #'l1',\n",
    "             'C':[0.001, 0.01, 0.1, 1, 2, 5, 10, 20, 100],\n",
    "             'solver':['lbfgs'],\n",
    "             'tol' : [10, 1, 0.1, 0.01, 0.001, 0.0001, 0.0001]\n",
    "}\n",
    "lm_search = GridSearchCV(estimator=lm, \n",
    "                         param_grid=lm_params, \n",
    "                         scoring ='accuracy', \n",
    "                         cv=StratifiedKFold(10), \n",
    "                         n_jobs=-1,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\anaconda_py\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6722762539613157\n",
      "Wall time: 1h 15min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lm_search_fitted = lm_search.fit(X=vectors_merged_train, y=y1)\n",
    "print(lm_search_fitted.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Увы__, результаты получились очень низкими. Возможно, стоило попробовать как-то иначе извлекать и обрабатывать токены, либо, использовать дополнительные линейные модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
